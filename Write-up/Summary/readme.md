# 운영체제
## 링커 / 로더
- 링커 : 컴파일러에 의해 번역된 목적 프로그램과 라이브러리 등을 연결하여 실행 가능한 모듈을 만드는 시스템웨어이다.(링킹 : 링커에 의해 수행되는 작업)
- 로더 : 보조기억장치로부터 주기억장치에 적재하는 시스템 소프트웨어이다.
### 기능
- 할당(Allocation) : 실행 프로그램을 실행하기 위해 기억장치 내에 옮겨놓을 공간을 확보하는 기능
- 연결(Liking) : 부프로그램 호출 시 그 부프로그램이 할당된 기억장소의 시작주소를 호출한 부분에 등록하여 연결하는 기능
- 재배치(Relocation) : 저장된 프로그램이 사용하는 각 주소들의 할당된 깅억장소의 실제 주소로 배치시키는 기능
- 적재(Loading) : 실행 프로그램을 할당된 기억공간에 실제로 옮기는 기능
### 종류
- Compile and Go 로더 : 별도의 로더 없이 번역 프로그램이 로더 기능까지 수행하는 방식
- Absolute Loader : 목적 프로그램을 기억 장소에 적재시키는 기능만 수행하는 로더
- 직접 연결 로더 : 일반적인 기능의 로더로 4가지를 모두 수행하는 로더
- 동적 적재 로더 : 시행 시 필요한 일부분만을 적재하는 로더로 Load-On-Call이라고도 함

## 프로세스
### 프로세스 정의
- 실행 중인 프로그램
- 운영체제가 관리하는 실행 단위
- 비동기적 행위를 일으키는 주체
- 프로시저가 활동중인 것
### Process와 Thread의 차이는 부모 프로세스와의 자원 공유 유무
- 자식프로세스는 생성될 때 부모 프로세스의 text 영역을 제외한 stack, heap, data 영역의 값들을 모두 복사해서 할당
- 스레드는 heap, data, text 영역을 공유하고 자기 자신의 stack 영역을 사용
- 시스템 콜
  1) Process : fork(), vfork()
  2) Thread : clone(), pthread()
### PCB(Process Control Block, 프로세스 제어 블록)
- 운영체제가 프로세스에 대한 중요한 정보를 저장해 놓은 곳
- 각 프로세스가 생성될 때마다 고유의 PCB가 생성되고, 프로세스가 완료되면 PCB는 제거
### 프로세스 상태 전이
- 프로세스 상태 : 생성, 준비, 실행, 완료 / 생성, 준비, 실행, 대기, 완료
- 준비(Ready) : 프로세스가 프로세서를 할당받기 위해 기다리고 있는 상태
- 프로세스는 준비상태 큐에서 실행을 준비하고 있다.
- 실행(Run) : 준비 상태 큐에 있는 프로세스가 프로세스를 할당받아 실행되는 상태
- 준비 상태에서 실행 상태로의 전이는 CPU(프로세서) 스케쥴러에 의해 수행
- 대기(Wait), 보류, Block : 입출력 요구가 발생되어 현재 실행중인 프로세스가 중단되고 완료될 때까지 기다리는 상태
- 완료 : 프로세스의 실행이 끝나고 프로세스 할당이 해제되어 PCB를 제거
- Spooling : 입출력장치의 공유 및 상대적인 느린 입출력장치의 처리 속도를 보완하고 다중 프로그래밍 시스템의 성능을 향상 시키기 위해 입출력할 데이터를 직접 입출력장치에 보내지 않고 나중에 한꺼번에 입출력하기 위해 디스크에 저장하는 과정
- Dispatch : 준비 상태에서 대기하고 있는 프로세스 중 하나가 프로세서를 할당받아 실행 상태로 전이되는 과정
- Wake up : 입출력 작업이 완료되어 프로세스가 대기 상태에서 준비상태로 전이되는 과정

## 스레드 (Thread)
### 스레드의 정의
- 프로세스 내에서의 작업 단위
- 시스템의 여러 자원을 할당받아 실행하는 프로그램 단위
- 프로세서의 일부 특성을 가지고 있어서 경량 프로세스(Light Weight)라고도 함
- 스레드는 독립된 제어 흐름을 가지며, 고유의 레지스터와 스택을 사용
- 스레드 기반 시스템에서 스레드는 독립적인 스케줄링의 최소 단위로서 프로세스의 역할을 담당
### 스레드 장점
- 하나의 프로세스를 여러 개의 스레드로 생성하여 병행성을 증진
- 하드웨어, 운영체제의 성능과 응용 프로그램의 처리율을 향상
- 응용프로그램의 응답 시간을 단축
- 실행 환경을 공유시켜 기억장소 및 자원의 낭비가 줄어든다.
- 공통적으로 접근 가능한 기억장치를 통해 효율적으로 통신

## 스케줄링
- 프로세스가 생성 실행될 때 시스템의 여러 자원을 해당 프로세스에게 할당하는 작업
### 목적
- 처리율, CPU 이용률 증가
- 공정성, 우선순위 제도, 균형 있는 자원의 사용, 무한 연기 회피
- 오버헤드, 응답 시간, 반환 시간, 대기 시간 최소화
### 문맥 교환
- 새로운 프로세스에게 CPU를 할당하기 위해 현재 CPU가 할당된 프로세스의 상태 정보를 저장하고, 새로운 프로세스의 상태 정보를 설정한 후 CPU를 할당하여 실행되도록 하는 작업
- 운영체제에서 Overhead가 발생되는 요인
### 비선점(Non Preemptive) 스케줄링
- 프로세스가 CPU를 할당받으면 해당 프로세스가 완료될 때까지 CPU를 사용
- 일괄 처리 방식
### 비선점 스케줄링 종류
1) FCFS (First Come First Service, 선입선출) : 큐에 도착한 순서에 따라 CPU를 할당
  - 문제점 : 호위 효과(Convoy Effect) : 수행 중인 긴 작업을 여러 개의 짧은 작업이 기다릴 수 있음
2) SJF (Shortest Job First, 최단 작업우선) : 실행시간이 가장 짧은 프로세스에 먼저 CPU를 할당하는 기법
  - 문제점 : CPU Burst Time(실행시간)은 미리 알기 어렵다. 장기 스케줄링에서는 유용하지만, 단기 스케줄링에서는 미리 알 수 없어 사용하기 어려움
3) HRN (Highest Response ratio) : 실행시간이 긴 프로세스에 불리한 SJF 기법을 보완하기 위한 기법
  - 우선순위 계산 결과 값이 높은 것부터 우선순위가 부여된다. 대기 시간이 길수록 계산 결과가 높다.
  - HRN 우선순위 = (대기시간+실행시간)/서비스시간
4) 우선순위 (Priority) : 우선순위가 높은 작업에 CPU를 할당, 우선순위가 낮은 작업은 무한 대기 상태가 발생할 수 있다.
  - 문제점 : 기아상태(Starvation) 유발, 즉 우선순위가 높은 작업이 계속 들어올 경우 우선순위가 낮은 작업이 준비 상태에서 보장없이 머물 수 있다.
  - 에이징(Aging) : 기아 상태 해결 방법, 시스템에 머무르는 시간이 증가하면 우선순위를 높여주는 것
### 선점(Preemptive) 스케줄링
- 선점으로 인한 많은 오버헤드가 발생한다.
- 시분할 시스템에 사용하는 스케줄링이다.
- 선점을 위해 시간 배당을 위한 인터럽트용 타이머 클럭(clock)이 필요하다.
### 선점 스케줄링 종류
1. SRT (Shortest Remaining Time) : SJF 알고리즘을 선점 형태로 변형한 기법
- 현재 실행 중인 프로세스의 남은 시간과 대기 큐에 프로세스의 실행 시간이 가장 짧은 프로세스가 CPU를 사용
2. RR (Round Robin) : FCFS를 선점 형태로 변형한 기법
- 시분할 시스템을 위해 고안
- 대기 큐를 사용하여 먼저 대기한 작업이 먼저 CPU를 사용한다. 
- CPU를 사용할 수 있는 시간(Quantum) 동안 CPU를 사용한 후에, 다시 대기 큐의 가장 뒤로에 배치하여 대기한다.
- 할당되는 시간이 클 경우 FCFS의 문제점(호위 효과)와 같아짐
- 할당되는 시간이 작을수록 문맥교환 및 오버헤드가 자주 발생된다.
3. MLQ (Multi Level Queue, 다단계큐) : 프로세스를 특정 그룹으로 분류할 수 있는 경우 그룹에 따라 각기 다른 준비상태 큐를 사용한다.
- 목적에 맞도록 우선순위들을 정하고, 그 우선순위마다 준비 큐를 따로 설정
4. MLFQ (Multi Level Feedback Queue, 다단계 피드백큐) : 특정 그룹의 준비상태 큐에 들어간 프로세스가 다른 준비상태 큐로 이동할수 없는 다단계 큐 기법을 적응기법으로 개선
5. RM (Rate Monotonic, 정적 우선순위) : 수행 주기가 가장 짧은 프로세스에 가장 높은 우선순위를 부여하는 방식
- 구현이 상대적으로 단순하고, 우선순위가 고정되기 때문에 예측성이 좋다.
- 하지만 CPU의 이용률이 좋지 않다는 단점	
6. EDF (Earliest Deadline First, 동적 우선순위) : 우선순위 큐에서 마감시간이 가장 가까운 프로세스를 탐색하여 실행
- RM 스케줄링은 사용률에 제약이 있는 반면, EDF는 스케줄링은 사용률이 1이하이기만 하면 스케줄링이 가능
- 현실적으로 프로세스의 마감시간을 예측하기 어려움.
- 과부하시 도미노 현상이 발생할 위험이 있음.

## 임계구역 / 상호배제 / 세마포어
### 임계 구역(Critical Section)
- 하나의 프로세스만 자원 또는 데이터를 사용하도록 지정된 공유 자원(영역)을 의미
- 특정 프로세스가 독점할 수 없다.
### 교착상태(Dead Lock)
- 경쟁 상태에서 다른 프로세스가 점유하고 있는 자원을 사용하기를 무한정 대기(Block)하는 상태
- 교착상태의 발생조건
 1. 상호 배제(Mutual Exclusion) : 프로그램들이 공유 자원을 동시에 쓸 수 없는 상황
 2. 점유 상태로 대기(Hold and Wait) : 공유자원을 점유한 상태에서 다른 자원을 기다리는 것
 3. 선점 불가(No prremption) : 자원을 어떤 프로세스가 점유 중일 때, 다른 프로세스가 그 자원을 뺏을 수 없음
 4. 순환성 대기(Circular wait) : 대기가 꼬리에 꼬리를 문 상황
### 상호 배제(Mutual Exclusion, Mutex)
- 여러 프로세스가 동시에 공유 자원을 사용하려 할 때 각 프로세스가 번갈아가며 공유 자원을 사용하도록 하는 임계 구역을 유지하는 방법
- 상호 배제 기법을 사용함으로써 임계 구역에서 인터럽트, 교착상태, 무한반복이 발생되지 않도록 해야한다.
- 상호 배제 알고리즘
 1. 데커(Dekker) 알고리즘 : flag와 turn이라는 변수로 임계영역에 들어갈 프로세스를 결정
- flag값은 프로세스 중 누가 임계영역에 진입할 것인지 나타내는 변수
- turn값은 누가 임계영역에 들어갈 차례인지 나타내는 변수
 2. 피터슨(Peterson) 알고리즘 : 다른 프로세스나 스레드에게 진입기회를 양보하는 기법
 3. 제과점(Bakery) 알고리즘 : 여러 개의 프로세스에 대한 처리가 가능, 가장 작은 수의 번호표를 가지고 있는 프로세스가 임계영역에 진입
 - 세마포어와 다른점 : 상호배제는 값이 1인 세마포어라고 할 수 있다.
### 세마포어
- 임계구역을 진입하기 어려울 때, 자발적으로 ‘대기(BLOCK)’상태에 들어가서 임계구역을 떠나는 프로세스가 대기상태에 있는 프로세스를 준비 상태로 깨워준다.
- 여러 개의 프로세스의 동기화에 사용
- 경쟁 자원을 사용하기 전에 임계영역에 진입할 수 있을 때까지 Wait
- 임계영역에 진입했을 때 P연산(Wait)으로 경쟁 자원 개수 1 감소
- 경쟁 자원을 사용한 후 임계 영역을 빠져나가기 전에 V연산(Signal)으로 경쟁 자원 개수 1 증가
- 정수값(value), 프로세스 대기큐(세마포어 대기큐), 정수에 대한 3가지 연산(init, wait(P연산), signal(V연산))
- 순위 역전 문제 : 높은 우선순위의 프로세스가 낮은 우선순위 프로세스가 자원 사용을 마칠 때까지 대기
- 상호 배제 기법을 사용함으로써 임계 구역에서 인터럽트, 교착상태, 무한반복이 발생되지 않도록 해야한다.

## 캐시 메모리
### 캐시 메모리란?
- 속도가 빠른 저장 장치와 느린 저장 장치 사이에 속도 차이에 따른 병목현상을 줄위기 위한 범용 메모리(버퍼)
- Main Memory와 CPU 사이에 존재하여 자주 쓰이는 데이터를 저장
- 지역성을 이용해 CPU가 어떤 데이터를 원할 것인가를 어느 정도 예측해 캐시 메모리에 데이터를 저장
### 지역성(Locality) 
- 어느 한 순간에 특정 부분을 집중적으로 참조하는 특성
1) 시간 지역성(Temporal Locality) : 최근에 참조된 주소의 내용이 재참조될 가능성이 높은 특성
2) 공간 지역성(Spatial Locality) : 최근에 참조된 주소의 인접한 데이터가 참조될 가능성이 높은 특성
### 적중(hit) / 실패(miss)
- CPU가 요청한 데이터가 캐시에 존재하면 cache hit, 없어서 메모리에서 가져온 경우 cache miss
1) Capacity Miss : 캐시 Memory가 작아서 발생하는 miss
2) Compulsory Miss : 특정 데이터에 처음 접근할 때, 캐시에 존재하지 않아서 발생하는 miss
3) Conflic Miss : 같은 캐시 메모리 주소에 할당되어서 발생하는 miss
### 메모리 사상(Mapping)
1) 직접 매핑 (Direct mapping)
- 메인 메모리를 일정한 크기의 블록으로 나누고, 각각의 블록을 캐시의 정해진 특정 위치에 매핑
- 특정 블록 내 데이터가 집중적으로 읽혀질 경우 캐시 실패(fault)가 자주 발생되는 단점
2) 완전 연관 사상 (Associative mapping)
- 메인 메모리의 내용이 캐시 메모리의 어느 위치에나 매핑이 가능한 사상 방법
 - 캐시 메모리 내 데이터 검색 시 전체 메모리를 스캔해야 하는 제약으로 고가의 메모리 사용 필요
3) 집합 연관 사상 (Set Associative mapping)
 - 캐시메모리를 세트로 구성하고, 메인 메모리가 세트에 대응되어 세트 내 자유롭게 매핑이 가능한 기법

## 주기억장치
### 배치 전략(Placement)
- 새로 반입되는 프로그램이나 데이터를 주기억장치의 어디에 위치시킬 것인지를 결정하는 전략
1) 최초 적합(First Fit) : 빈 영역 중에서 첫 번째 분할 영역에 배치시키는 방법
2) 최적 적합(Best Fit) : 빈 영역 중에서 단편화를 가장 작게 남기는 분할 영역에 배치시키는 방법
3) 최악 적합(Worst Fit) : 빈 영역 중에서 단편화를 가장 많이 남기는 분할 영역에 배치시키는 방법
### 주기억장치 단일 분할 할당 기법
1) 오버레이 기법
- 주기억장치보다 큰 사용자 프로그램을 실행하기 위한 기법
- 주기억장치의 공간이 부족하면 주기억장치에 적재된 프로그램의 조각 중 불필요한 조각이 위치한 장소에 새로운 프로그램의 조각을 중첩(overlay)하여 적재
2) 스와핑
- 프로그램 전체를 주기억장치에 할당하여 사용하다 필요에 따라 다른 프로그램과 교체하는 기법
- Swap out : 주기억장치에 있는 프로그램이 보조기억장치로 이동하는 것
- Swap in : 보조기억장치에 있는 프로그램이 주기억장치로 이동되는 것
### 주기억장치 다중 분할 할당 기법
1) 고정 분할 할당(MFT, 정적 할당 기법)
- 프로그램을 할당하기 전에 운영체제가 주기억장치의 사용자 영역을 여러 개의 고정된 크기를 분할하고, 준비상태 큐에서 준비중인 프로그램을 각 영역에 할당하여 수행
- 내부 단편화 및 외부 단편화가 발생하여 주기억장치의 낭비가 많다.
2) 가변 분할 할당(MVT, 동적 할당 기법)
- 프로그램을 주기억장치에 적재하면서 필요한 만큼의 크기로 영역을 분할하는 기법
- 단편화를 상당 부분 해결할 수 있으나 영역과 영역 사이에 단펺화가 발생할 수 있다.

## 가상기억장치
### 페이징(Paging) 기법
- 가상기억장치에 보관되어 있는 프로그램과 주기억장치의 영역을 동힐한 크기로 나눈 후 나눠진 프로그램(페이지)을 동일하게 나눠진 주기억장치의 영역(페이지 프레임)에 적재시켜 실행하는 기법
- 페이지(Page) : 프로그램을 일정한 크기로 나눈 단위
- 페이지 프레임(Page Frame) : 페이지 크기로 일정하게 나누어진 주기억장치의 단위
- 외부 단편화는 발생하지 않으나, 내부 단편화는 발생
- 주소 변화를 위해서 페이지 위치 정보를 가지고 있는 페이지 맵 테이블(Page Map Table)이 필요
### 세그먼테이션(Segmentation) 기법
- 가상기억장치에 보관되어 있는 프로그램을 다양한 크기의 논리적인 단위로 나눈 후 주기억장치에 적재시켜 실행
- 기억공간을 절약하기 위해서 사용
- 주소 변환을 위해서 세그먼트가 존재하는 위치 정보를 가지고 있는 세그먼트 맵 테이블(Segment Map Table)이 필요
- 다른 세그먼트에게 할당된 영역을 침벌할 수 없으며, 기억장치 보호키(Storage Protection Key)가 필요
- 내부 단편화는 발생하지 않으나, 외부 단편화는 발생
### 페이지 교체 알고리즘
- 페이지 부재(Page Fault) : CPU가 액세스한 가상 페이지가 주기억장치에 없는 경우
  1) OPT(OPTimal replacement, 최적 교체) : 가장 오랫동안 사용하지 않을 페이지를 교체
  2) FIFO(First In First Out, 선입선출) : 가장 먼저 들어와서 가장 오래 있었던 페이지를 교체
  3) LRU(Least Recently Used)) : 최근에 가장 오랫동안 사용하지 않은 페이지를 교체
  4) LFU(Least Frequently Used) : 사용 빈도가 가장 적은 페이지를 교체
  5) NUR(Not Used Recently) : 최근에 사용하지 않는 페이지를 교체
      - LRU에서 나타나는 시간적인 오버헤드를 줄일 수 있음.
      - 참조비트(Reference Bit), 변형비트(Modified Bit, Dirty Bit)
      - 교체순서 : 1순위(참조0, 변형0), 2순위(참조0, 변형1), 3순위(참조1, 변형0), 4순위(참조1, 변형1) // 참조 > 변형
  6) SCR(Second Chance Replacement, 2차 기회 교체)
      - 가장 오랫동안 주기억장치에 있던 페이지 중 가장 자주 사용되는 페이지의 교체를 방지
      - FIFO 기법의 단점을 보완한 기법
### 페이지 Locality
1. 시간 구역성(Temporal Localtiy)
- 프로세스가 실행되면서 하나의 페이지를 일정 시간 동안 집중적으로 액세스하는 현상
- 한번 참조한 페이지는 가까운 시간 내에 계속 참조할 가능성이 높음
- Loop(반복, 순환), 스택(Stack), 부 프로그램(Sub Routine), Counting(증감), 집계(Totaling)에 사용되는 변수(기억장소)
2. 공간 구역성(Spatial Localtiy)
- 프로세스 실 시 일정 위치의 페이지를 집중적으로 액세스 하는 현상
- 어느 하나의 페이지를 참조하면 그 근처의 페이지를 계속 참조할 가능성이 높음
- 배열 순회(Array), 순차적 코드의 실행, 근처에 선언하여 할당되는 기억 장소, 같은 영역에 있는 변수를 참조할 때 사용
### 워킹셋(Working Set)
- 프로세스가 일정 시간 동안 자주 참조하는 페이지들의 집합
- 자주 참조되는 워킹 셋을 주기억장치에 상주시킴으로써 페이지 부재 및 페이지 교체 현상을 줄임
- 시간이 지남에 따라 자주 참조되는 페이지들의 집합이 변화하기 때문에 워킹 셋은 시간에 따라 변화
### 페이지 부재 빈도 방식
- 페이지 부재(Page Fault): 프로세스 실행 시 참조할 페이지가 주기억장치에 없는 현상
- 페이지 부재 빈도(PFF, Page Fault Frequency) : 페이지 부재가 일어나는 횟수
- 페이지 부재율에 따라 주기억장치에 있는 페이지 프레임의 수를 늘리거나 줄여 페이지 부재율을 적정 수준으로 유지하는 방식
### 프리페이징(Prepaging)
- 처음의 과도한 페이지 부재를 방지하기 위해, 필요할 것 같은 모든 페이지를 한꺼번에 페이지 프레임에 적재하는 기법
### 스래싱(Thrashing)
- 프로세스의 처리 시간보다 페이지 교체에 소요되는 시간이 더 많아지는 현상
- 다중 프로그래밍의 정도가 높아짐에 따라 CPU의 이용률은 어느 특정 시점까지는 높아지지만, 다중 프로그래밍의 정도가 더욱 커지면 스래싱이 나타나고, CPU의 이용률은 급격히 감소하게 된다.
- 스래싱 현상 방지 방법
  1) 다중 프로그래밍의 정도를 적정 수준 유지
  2) 페이지 부재 빈도를 조절
  3) 워킹 셋을 유지
  4) CPU 성능을 지속적 관리 및 분석으로 임계치를 예상하여 운영
